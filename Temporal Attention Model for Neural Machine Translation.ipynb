{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [WORK IN PROGRESS]\n",
    "# Temporal Attention Model for Neural Machine Translation\n",
    "Unofficial implementation of paper: http://arxiv.org/abs/1608.02927\n",
    "\n",
    "### Requirements:\n",
    " - [Keras](https://github.com/fchollet/keras)\n",
    " - [Tensorflow](https://github.com/tensorflow/tensorflow)\n",
    " - [Theano](https://github.com/Theano/Theano)\n",
    " - https://github.com/farizrahman4u/seq2seq Seq2Seq implemtation built on top of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading (French, English) language pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.models.rnn.translate import data_utils\n",
    "data_dir = \"/data/translate\" # You may need to change that or create a sympolic link\n",
    "vocab_size = 20000\n",
    "pathes = data_utils.prepare_wmt_data(data_dir, vocab_size, vocab_size)\n",
    "en2_path, fr2_path, en2013_path, fr2013_path, en_vocab_path, fr_vocab_path = pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "# https://github.com/nicolas-ivanov/tf_seq2seq_chatbot/blob/master/tf_seq2seq_chatbot/lib/data_utils.py\n",
    "\n",
    "_PAD = \"_PAD\"\n",
    "_GO = \"_GO\"\n",
    "_EOS = \"_EOS\"\n",
    "_UNK = \"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "PAD_ID = 0\n",
    "GO_ID = 1\n",
    "EOS_ID = 2\n",
    "UNK_ID = 3\n",
    "\n",
    "# Regular expressions used to tokenize.\n",
    "_WORD_SPLIT = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "_DIGIT_RE = re.compile(r\"\\d{3,}\")\n",
    "\n",
    "def read_vocab(vocab_path):\n",
    "    vocab_list = []\n",
    "    vocab_list.extend(_START_VOCAB)\n",
    "\n",
    "    with open(vocab_path, 'br') as f:\n",
    "        vocab_list.extend([s.decode(\"utf-8\").strip() for s in f.readlines() if is_ascii(s)])\n",
    "\n",
    "    words_to_ids = {w:i for (i, w) in enumerate(vocab_list)}\n",
    "    ids_to_words = {i:w for (w, i) in words_to_ids.items()}\n",
    "    return ids_to_words, words_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_index, en_vocab = read_vocab(en_vocab_path)\n",
    "fr_index, fr_vocab = read_vocab(fr_vocab_path)\n",
    "\n",
    "def basic_tokenizer(sentence):\n",
    "    \"\"\"Very basic tokenizer: split the sentence into a list of tokens.\"\"\"\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(re.split(_WORD_SPLIT, space_separated_fragment))\n",
    "    return [w.lower() for w in words if w]\n",
    "\n",
    "def sentence_to_token_ids(sentence, vocabulary,\n",
    "                          tokenizer=None, normalize_digits=True):\n",
    "    \"\"\"Convert a string to list of integers representing token-ids.\n",
    "\n",
    "    For example, a sentence \"I have a dog\" may become tokenized into\n",
    "    [\"I\", \"have\", \"a\", \"dog\"] and with vocabulary {\"I\": 1, \"have\": 2,\n",
    "    \"a\": 4, \"dog\": 7\"} this function will return [1, 2, 4, 7].\n",
    "\n",
    "    Args:\n",
    "    sentence: a string, the sentence to convert to token-ids.\n",
    "    vocabulary: a dictionary mapping tokens to integers.\n",
    "    tokenizer: a function to use to tokenize each sentence;\n",
    "      if None, basic_tokenizer will be used.\n",
    "    normalize_digits: Boolean; if true, all digits are replaced by 0s.\n",
    "\n",
    "    Returns:\n",
    "    a list of integers, the token-ids for the sentence.\n",
    "    \"\"\"\n",
    "    if tokenizer:\n",
    "        words = tokenizer(sentence)\n",
    "    else:\n",
    "        words = basic_tokenizer(sentence)\n",
    "    if not normalize_digits:\n",
    "        return [vocabulary.get(w, UNK_ID) for w in words]\n",
    "  \n",
    "    # Normalize digits by 0 before looking words up in the vocabulary.\n",
    "    return [vocabulary.get(re.sub(_DIGIT_RE, \"0\", w), UNK_ID) for w in words]\n",
    "\n",
    "def token_ids_to_sentence(ids, vocab_index):\n",
    "    maybe_words = [vocab_index.get(_id) for _id in ids]\n",
    "    return \" \".join([w for w in maybe_words if w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FIXME: some non-ascii charachters\n",
    "en_vocab_size = len(en_vocab) + 1\n",
    "fr_vocab_size = len(fr_vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19905\n",
      "19905\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(len(en_vocab))\n",
    "print(len(en_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15239, 22, 1511, 614, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a is me strategy'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = sentence_to_token_ids(\"A is me strategy stratégie\", en_vocab)\n",
    "print(ids)\n",
    "token_ids_to_sentence(ids, en_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/translate/giga-fren.release2.ids20000.en',\n",
       " '/data/translate/giga-fren.release2.ids20000.fr',\n",
       " '/data/translate/newstest2013.ids20000.en',\n",
       " '/data/translate/newstest2013.ids20000.fr',\n",
       " '/data/translate/vocab20000.en',\n",
       " '/data/translate/vocab20000.fr')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return [[int(x) for x in line.split(\" \")] for line in f.read().splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# e.g. [59, 3, 610, 9, 6251, 4, 3, 7, 3]\n",
    "en_ids = read_data(en2013_path)\n",
    "fr_ids = read_data(fr2013_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "# Make it the same length (= the max length of the sentences) with zeros for shorter sentences\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "en_set = pad_sequences(en_ids)\n",
    "fr_set = pad_sequences(fr_ids)\n",
    "en_max_length = en_set.shape[1]\n",
    "fr_max_length = fr_set.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base mieux génétiquement du _UNK'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_sentence(fr_set[0], fr_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_max_features = max(en_vocab.values())\n",
    "fr_max_features = max(fr_vocab.values())\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 3000\n",
      "en_max_length: 110\n",
      "fr_max_length: 126\n",
      "en_max_features: 20003\n",
      "fr_max_features: 20003\n",
      "embedding_size: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"number of samples:\", en_set.shape[0])\n",
    "print(\"en_max_length:\", en_max_length)\n",
    "print(\"fr_max_length:\", fr_max_length)\n",
    "print(\"en_max_features:\", en_max_features)\n",
    "print(\"fr_max_features:\", fr_max_features)\n",
    "print(\"embedding_size:\", embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_set.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding layer for en and fr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge, Dropout, RepeatVector, Permute, Activation, recurrent, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 110, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(en_max_features, embedding_size, input_length=en_max_length, mask_zero=True))\n",
    "model.compile('rmsprop', 'mse')\n",
    "en_embed = model.predict(en_set)\n",
    "en_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 126, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(fr_max_features, embedding_size, input_length=fr_max_length, mask_zero=True))\n",
    "model.compile('rmsprop', 'mse')\n",
    "fr_embed = model.predict(fr_set)\n",
    "fr_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 126, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment  1\n",
    "hidden_size = 32\n",
    "model = Sequential()\n",
    "model.add(GRU(hidden_size, input_shape=(en_max_length, embedding_size))) # (3000, 110, 64) -> (3000, 32)\n",
    "model.add(RepeatVector(fr_max_length)) # (3000, 32) -> (3000, 126, 32)\n",
    "# model.add(TimeDistributed(Dense(fr_max_length)))\n",
    "model.add(Bidirectional(GRU(embedding_size, return_sequences=True), merge_mode='sum')) # (3000, 126, 32) -> (3000, 126, 64)\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 110)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Embedding',\n",
       "  'config': {'W_constraint': None,\n",
       "   'W_regularizer': None,\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 110),\n",
       "   'dropout': 0.0,\n",
       "   'init': 'uniform',\n",
       "   'input_dim': 20003,\n",
       "   'input_dtype': 'int32',\n",
       "   'input_length': 110,\n",
       "   'mask_zero': True,\n",
       "   'name': 'embedding_10',\n",
       "   'output_dim': 64,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Bidirectional',\n",
       "  'config': {'layer': {'class_name': 'GRU',\n",
       "    'config': {'U_regularizer': None,\n",
       "     'W_regularizer': None,\n",
       "     'activation': 'tanh',\n",
       "     'b_regularizer': None,\n",
       "     'consume_less': 'cpu',\n",
       "     'dropout_U': 0.0,\n",
       "     'dropout_W': 0.0,\n",
       "     'go_backwards': False,\n",
       "     'init': 'glorot_uniform',\n",
       "     'inner_activation': 'hard_sigmoid',\n",
       "     'inner_init': 'orthogonal',\n",
       "     'input_dim': 64,\n",
       "     'input_length': None,\n",
       "     'name': 'forward_gru_16',\n",
       "     'output_dim': 32,\n",
       "     'return_sequences': False,\n",
       "     'stateful': False,\n",
       "     'trainable': True,\n",
       "     'unroll': False}},\n",
       "   'merge_mode': 'sum',\n",
       "   'name': 'bidirectional_8',\n",
       "   'trainable': True}},\n",
       " {'class_name': 'RepeatVector',\n",
       "  'config': {'n': 126, 'name': 'repeatvector_8', 'trainable': True}},\n",
       " {'class_name': 'GRU',\n",
       "  'config': {'U_regularizer': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'tanh',\n",
       "   'b_regularizer': None,\n",
       "   'consume_less': 'cpu',\n",
       "   'dropout_U': 0.0,\n",
       "   'dropout_W': 0.0,\n",
       "   'go_backwards': False,\n",
       "   'init': 'glorot_uniform',\n",
       "   'inner_activation': 'hard_sigmoid',\n",
       "   'inner_init': 'orthogonal',\n",
       "   'input_dim': 32,\n",
       "   'input_length': None,\n",
       "   'name': 'gru_17',\n",
       "   'output_dim': 64,\n",
       "   'return_sequences': False,\n",
       "   'stateful': False,\n",
       "   'trainable': True,\n",
       "   'unroll': False}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'W_constraint': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'softmax',\n",
       "   'activity_regularizer': None,\n",
       "   'b_constraint': None,\n",
       "   'b_regularizer': None,\n",
       "   'bias': True,\n",
       "   'init': 'glorot_uniform',\n",
       "   'input_dim': None,\n",
       "   'name': 'dense_7',\n",
       "   'output_dim': 126,\n",
       "   'trainable': True}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment  2\n",
    "hidden_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(en_max_features, embedding_size, input_length=en_max_length, mask_zero=True))\n",
    "model.add(Bidirectional(GRU(hidden_size), merge_mode='sum'))\n",
    "print(model.input_shape)\n",
    "model.add(RepeatVector(fr_max_length))\n",
    "model.add(GRU(embedding_size))\n",
    "# print(model.output_shape)\n",
    "model.add(Dense(fr_max_length, activation=\"softmax\"))\n",
    "# print(model.output_shape)\n",
    "model.compile('rmsprop', 'mse')\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 86s - loss: 2416187.9463    \n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 83s - loss: 2416181.1993    \n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 84s - loss: 2416181.1720    \n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 84s - loss: 2416181.1713    \n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 85s - loss: 2416181.1747    \n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 84s - loss: 2416181.1763    \n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 83s - loss: 2416181.1727    \n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 82s - loss: 2416181.1727    \n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 82s - loss: 2416181.1660    \n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 83s - loss: 2416181.1607    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9872e86160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(en_set, fr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Translator(object):\n",
    "    def __init__(self, model, source, target):\n",
    "        self.model = model\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "    \n",
    "    def translate(self, sentence):\n",
    "        ids = sentence_to_token_ids(sentence, self.source)\n",
    "        print(ids)\n",
    "        x = pad_sequences([ids], maxlen=en_max_length)\n",
    "        print(x)\n",
    "        print(model.predict(x))\n",
    "        p = [np.argmax(i) for i in model.predict(x)]\n",
    "        print(p)\n",
    "        return token_ids_to_sentence(p, self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[498, 5108, 781, 611, 22]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0  498 5108  781  611   22]]\n",
      "[[  1.68755662e-10   1.68414185e-10   1.68901212e-10   1.68291839e-10\n",
      "    1.68502226e-10   1.68551076e-10   1.68695807e-10   1.68722522e-10\n",
      "    1.68200384e-10   1.68550437e-10   1.68651093e-10   1.68976624e-10\n",
      "    1.68677142e-10   1.68717373e-10   1.68748904e-10   1.68411618e-10\n",
      "    1.68701275e-10   1.69265962e-10   1.68368569e-10   1.69050440e-10\n",
      "    1.68545289e-10   1.68507680e-10   1.68874484e-10   1.68432171e-10\n",
      "    1.68316236e-10   1.68505113e-10   1.68396838e-10   1.68732500e-10\n",
      "    1.68737649e-10   1.69523146e-10   1.68629541e-10   1.68729281e-10\n",
      "    1.68761144e-10   1.68611208e-10   1.68476830e-10   1.69137204e-10\n",
      "    1.68870945e-10   1.68770470e-10   1.68661390e-10   1.68825204e-10\n",
      "    1.68658490e-10   1.69011430e-10   1.68817807e-10   1.68650441e-10\n",
      "    1.68697098e-10   1.69064304e-10   1.68823275e-10   1.68821027e-10\n",
      "    1.68753414e-10   1.69082040e-10   1.68729919e-10   1.68914743e-10\n",
      "    1.70048739e-10   1.70059120e-10   1.69151401e-10   1.69992964e-10\n",
      "    1.69926184e-10   1.68822636e-10   1.69283074e-10   1.69384173e-10\n",
      "    1.69816675e-10   1.70461811e-10   1.70178857e-10   1.70154182e-10\n",
      "    1.69964764e-10   1.71418421e-10   1.70754355e-10   1.70798972e-10\n",
      "    1.71996792e-10   1.71509001e-10   1.72755615e-10   1.74802006e-10\n",
      "    1.72807352e-10   1.73418196e-10   1.73555198e-10   1.74578102e-10\n",
      "    1.74627049e-10   1.75443660e-10   1.75019194e-10   1.76877360e-10\n",
      "    1.74834022e-10   1.77105566e-10   1.76536619e-10   1.79358042e-10\n",
      "    1.78352708e-10   1.84135013e-10   1.85395935e-10   1.82718785e-10\n",
      "    1.82541829e-10   1.85876065e-10   1.89828320e-10   1.91701433e-10\n",
      "    1.94787894e-10   1.90952601e-10   1.95846644e-10   1.97676181e-10\n",
      "    1.96866842e-10   2.00329697e-10   2.09070997e-10   2.06598585e-10\n",
      "    2.15717902e-10   2.17097354e-10   2.18097179e-10   2.29711555e-10\n",
      "    2.29164090e-10   2.46913157e-10   2.49439913e-10   2.42401266e-10\n",
      "    2.60296312e-10   2.71471873e-10   2.66561051e-10   2.90748398e-10\n",
      "    2.90902052e-10   3.02436048e-10   3.06065256e-10   3.21276533e-10\n",
      "    3.32495059e-10   3.30934835e-10   3.30502098e-10   3.67627345e-10\n",
      "    3.51991492e-10   3.75889847e-10   3.36538908e-10   3.33949868e-10\n",
      "    1.00000000e+00   1.75644554e-10]]\n",
      "[124]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projet'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Translator(model, en_vocab, fr_index)\n",
    "t.translate(\"good morning my name is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 28s - loss: 4.2822e-04    \n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 20s - loss: 3.4502e-04    \n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 20s - loss: 3.3201e-04    \n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 19s - loss: 3.2797e-04    \n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 20s - loss: 3.2646e-04    \n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 20s - loss: 3.2522e-04    \n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 20s - loss: 3.2371e-04    \n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 21s - loss: 3.1993e-04    \n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 20s - loss: 2.9921e-04    \n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 20s - loss: 2.8977e-04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3c2a97390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 32\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(hidden_size, input_shape=(en_max_length, embedding_size))) # (3000, 110, 64) -> (3000, 32)\n",
    "model2.add(RepeatVector(fr_max_length)) # (3000, 32) -> (3000, 126, 32)\n",
    "model2.add(GRU(hidden_size, return_sequences=True)) # (3000, 126, 32) -> (3000, 126, 32)\n",
    "model2.add(TimeDistributed(Dense(embedding_size))) # (3000, 126, 32) -> (3000, 126, 64)\n",
    "model2.compile('rmsprop', 'mse')\n",
    "\n",
    "model2.fit(en_embed, fr_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = model.predict(en_embed[0:1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.40153063e-03,  -3.22375521e-02,  -4.75068614e-02,\n",
       "        -2.59117223e-03,  -2.95166131e-02,   1.46325864e-02,\n",
       "        -3.98642495e-02,   2.95883510e-02,  -3.17148454e-02,\n",
       "         1.59019846e-02,  -1.05737150e-02,  -1.79499127e-02,\n",
       "         1.94397233e-02,   3.81198898e-02,  -2.59830933e-02,\n",
       "        -2.92450693e-02,   4.51442190e-02,   5.08413278e-02,\n",
       "         7.33843120e-03,   4.26314175e-02,   3.46514620e-02,\n",
       "         4.70041372e-02,  -3.75328921e-02,  -2.33594934e-03,\n",
       "        -3.55315693e-02,   3.93421836e-02,  -4.57464680e-02,\n",
       "         3.86401005e-02,  -3.11844051e-05,  -1.57241561e-02,\n",
       "        -4.18174230e-02,   2.74838321e-03,  -2.36382075e-02,\n",
       "        -3.04609593e-02,   1.96134159e-03,  -3.08620632e-02,\n",
       "        -1.56029891e-02,  -3.90794612e-02,   2.88303830e-02,\n",
       "        -3.90990563e-02,  -3.89516950e-02,  -1.03248246e-02,\n",
       "         2.34307814e-02,   5.00837490e-02,   3.29555683e-02,\n",
       "         2.49449313e-02,   3.69495414e-02,  -4.72858250e-02,\n",
       "        -3.78020816e-02,   3.78629193e-02,   3.24805938e-02,\n",
       "         1.31934723e-02,  -3.21865827e-02,   1.13256890e-02,\n",
       "        -9.78391152e-03,  -5.31859230e-03,  -3.97230946e-02,\n",
       "        -4.90802377e-02,  -2.86601558e-02,   2.00279076e-02,\n",
       "        -3.57138067e-02,  -2.11647004e-02,   3.67628895e-02,\n",
       "        -3.83040160e-02], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model infered from Seq2Seq\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_dim, return_sequences=True, mask_zero=True))\n",
    "model.add(Dropout(droupout))\n",
    "model.add(LSTM(hidden_dim, )) # Encoder\n",
    "model.add(Dropout(droupout))\n",
    "model.add(RepeatVecotr(output_lenght))\n",
    "model.add(LSTM(hidden_dim, return_sequences=True, )) # Decoder\n",
    "model.add(LSTM(hidden_dim, return_sequences=True, ))\n",
    "model.add(Droupout(droupout))\n",
    "model.add(TimeDistributed(Dense(output_dim)))\n",
    "model.compile('rmsprop', 'mse')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/fchollet/keras/issues/395\n",
    "\n",
    "In the model I listed below with the english sentence as input and the entire french sentence as output. The RNN model will maintain state across each timestep as it predicts the output sentence, no extra work required on your behalf. You will however need to one hot encode and zero pad the output sequence (the french sentence) and have it do a softmax over all possible words for the output at each time step. The ys then are 3D, each row is a matrix of height - number of french words, and width - number of time steps.\n",
    "\n",
    "```python\n",
    "embedding_size = 50\n",
    "hidden_size = 512\n",
    "output_size = 20\n",
    "maxlen = 60\n",
    "\n",
    "model = Sequential()\n",
    "model.add(JZS1(embedding_size, hidden_size)) # try using a GRU instead, for fun\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(RepeatVector(maxlen))\n",
    "model.add(JZS1(hidden_size, hidden_size, return_sequences=True))\n",
    "model.add(TimeDistributedDense(hidden_size, output_size, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "embedding_size = 64\n",
    "hidden_size = 512\n",
    "embedding_size = EN_REPRESENTATION_SIZE\n",
    "MAX_LEN = fr_set.shape[1]\n",
    "max_features = FR_BOUND\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(EN_REPRESENTATION_SIZE, EMBED_HIDDEN_SIZE, input_length=en_set.shape[1], mask_zero=True))\n",
    "model.add(GRU(hidden_size)) # try using a GRU instead, for fun\n",
    "model.add(Dense(hidden_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(RepeatVector(MAX_LEN))\n",
    "model.add(GRU(hidden_size, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(max_features, activation=\"softmax\")))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seq2seq\n",
    "from seq2seq.models import SimpleSeq2seq\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(EN_REPRESENTATION_SIZE, EMBED_HIDDEN_SIZE, input_length=en_set.shape[1]))\n",
    "model = SimpleSeq2seq(\n",
    "        input_dim=EN_REPRESENTATION_SIZE,\n",
    "        input_length=en_max_length,\n",
    "        hidden_dim=50,\n",
    "        output_length=FR_REPRESENTATION_SIZE,\n",
    "        output_dim=fr_max_length)\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.fit(en_embed, fr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RNN = GRU\n",
    "# EMBED_HIDDEN_SIZE = 50\n",
    "\n",
    "# encoder = Sequential()\n",
    "# encoder.add(Embedding(en_vocab_size, EMBED_HIDDEN_SIZE, input_length=en_max_length))\n",
    "\n",
    "# decoder = Sequential()\n",
    "# decoder.add(Embedding(fr_vocab_size, EMBED_HIDDEN_SIZE, input_length=fr_max_length))\n",
    "\n",
    "# decoder.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "# decoder.add(RepeatVector(en_max_length))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Merge([encoder, decoder], mode='sum'))\n",
    "# model.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(fr_vocab_size, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p = model.predict([en_set, fr_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# outputs = [int(np.argmax(logit, axis=0)) for logit in p[0]][0:fr_input_length]\n",
    "# token_ids_to_sentence(outputs, fr_index)\n",
    "# # [fr_ids[output] for output in outputs]\n",
    "# # print(\" \".join([tf.compat.as_str(fr_ids[output]) for output in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ord() expected string of length 1, but int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e0d5f9b7ac4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'_UNK\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-69a543447130>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# https://github.com/nicolas-ivanov/tf_seq2seq_chatbot/blob/master/tf_seq2seq_chatbot/lib/data_utils.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ord() expected string of length 1, but int found"
     ]
    }
   ],
   "source": [
    "list(is_ascii(b'_UNK\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
