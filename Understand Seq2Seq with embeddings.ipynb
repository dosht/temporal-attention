{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import seq2seq\n",
    "from seq2seq.models import SimpleSeq2seq\n",
    "\n",
    "model = SimpleSeq2seq(input_dim=5, hidden_dim=10, output_length=8, output_dim=8)\n",
    "model.compile(loss='mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'LSTM',\n",
       "  'config': {'U_regularizer': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'tanh',\n",
       "   'b_regularizer': None,\n",
       "   'batch_input_shape': (None, None, 5),\n",
       "   'consume_less': 'cpu',\n",
       "   'dropout_U': 0.0,\n",
       "   'dropout_W': 0.0,\n",
       "   'forget_bias_init': 'one',\n",
       "   'go_backwards': False,\n",
       "   'init': 'glorot_uniform',\n",
       "   'inner_activation': 'hard_sigmoid',\n",
       "   'inner_init': 'orthogonal',\n",
       "   'input_dim': 5,\n",
       "   'input_dtype': 'float32',\n",
       "   'input_length': None,\n",
       "   'name': 'lstm_1',\n",
       "   'output_dim': 10,\n",
       "   'return_sequences': False,\n",
       "   'stateful': False,\n",
       "   'trainable': True,\n",
       "   'unroll': False}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_1', 'p': 0.25, 'trainable': True}},\n",
       " {'class_name': 'RepeatVector',\n",
       "  'config': {'n': 8, 'name': 'repeatvector_1', 'trainable': True}},\n",
       " {'class_name': 'LSTM',\n",
       "  'config': {'U_regularizer': None,\n",
       "   'W_regularizer': None,\n",
       "   'activation': 'tanh',\n",
       "   'b_regularizer': None,\n",
       "   'batch_input_shape': (None, None, 5),\n",
       "   'consume_less': 'cpu',\n",
       "   'dropout_U': 0.0,\n",
       "   'dropout_W': 0.0,\n",
       "   'forget_bias_init': 'one',\n",
       "   'go_backwards': False,\n",
       "   'init': 'glorot_uniform',\n",
       "   'inner_activation': 'hard_sigmoid',\n",
       "   'inner_init': 'orthogonal',\n",
       "   'input_dim': 10,\n",
       "   'input_dtype': 'float32',\n",
       "   'input_length': None,\n",
       "   'name': 'lstm_2',\n",
       "   'output_dim': 10,\n",
       "   'return_sequences': True,\n",
       "   'stateful': False,\n",
       "   'trainable': True,\n",
       "   'unroll': False}},\n",
       " {'class_name': 'TimeDistributed',\n",
       "  'config': {'layer': {'class_name': 'Dense',\n",
       "    'config': {'W_constraint': None,\n",
       "     'W_regularizer': None,\n",
       "     'activation': 'linear',\n",
       "     'activity_regularizer': None,\n",
       "     'b_constraint': None,\n",
       "     'b_regularizer': None,\n",
       "     'bias': True,\n",
       "     'init': 'glorot_uniform',\n",
       "     'input_dim': None,\n",
       "     'name': 'dense_1',\n",
       "     'output_dim': 8,\n",
       "     'trainable': True}},\n",
       "   'name': 'timedistributed_1',\n",
       "   'trainable': True}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Merge, Dropout, RepeatVector, Permute, Activation, recurrent, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "en_max_length = 110\n",
    "fr_max_length = 126\n",
    "en_max_features = 20003\n",
    "fr_max_features = 20003\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 110)\n",
      "(None, 126)\n"
     ]
    }
   ],
   "source": [
    "# Experiment  2\n",
    "hidden_size = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(en_max_features, embedding_size, input_length=en_max_length, mask_zero=True))\n",
    "model.add(Bidirectional(GRU(hidden_size, return_sequences=True), merge_mode='sum'))\n",
    "# model.add(RepeatVector(fr_max_length))\n",
    "model.add(TimeDistributed(Dense(embedding_size)))\n",
    "model.add(GRU(embedding_size))\n",
    "model.add(Dense(fr_max_length, activation=\"softmax\"))\n",
    "model.compile('rmsprop', 'mse')\n",
    "model.get_config()\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
